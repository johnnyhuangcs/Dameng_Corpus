

# 运维监控工具

## 一、前言

数据库运维监控系统可以为数据库稳定运行提供重要保障。如果可以建立起可靠的运维监控系统，对可能发生的灾难加以预警，就能迅速启动应急响应机制，排除系统故障，这对于保障系统稳定运行具有极大的价值。
本文主要介绍达梦数据库常用的四种运维监控工具：

  * 达梦企业管理器 DEM
  * 达梦 SQL 日志分析工具 DMLOG
  * 开源性能监控工具 NMON（Linux）
  * 开源运维监控工具 Prometheus



## 二、达梦企业管理器 DEM

### 2.1 工具介绍

达梦企业管理器（DM Enterprise Manager，简称为 DEM ）提供一个通过 Web 界面来监控、管理并维护 DM 数据库的集中式管理平台。数据库管理员可通过任意 Web 应用登录 DEM，从而对 DM 数据库进行管理和监控。 DEM 主要有集群部署、自动巡检、监控和告警等功能。DEM 由以下几个部分组成：

  * DEM 服务器：指 DEM 应用服务器，负责处理客户端工具功能逻辑并存储 dmagent 收集到的数据到 DEM 存储数据库，同时向客户端展示监控数据。
  * DEM 存储数据库：存储 DEM 的元数据和 dmagent 收集到的监控数据。
  * 数据库实例：需要被管理监控的数据库实例。
  * 数据库代理服务（dmagent）：部署在远程机器上的代理，DEM 通过 dmagent 访问远程主机，同时 dmagent 收集监控信息发送给 DEM。



DEM 系统架构图如下所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009143353L2OTCYVBQH39VLGMQV)

DEM 工具主要提供如下功能：

  * 客户端工具。用户能够通过 DEM 工具来进行 DM 数据库的对象管理、状态监控、SQL 查询与调试。
  * 监控与告警。本功能是 DEM 工具的核心功能。通过远程主机部署代理，能够实现对远程主机状态和远程主机上 DM 数据库实例状态的监控。DEM 监控功能不仅仅局限于单个数据库实例，还能够对数据库集群（MPP、RAC、数据守护等）进行监控和管理。
  * 系统管理。DEM 工具提供了工具本身的系统配置与权限管理，方便不同用户同时使用工具，也可限制非 admin 用户的权限。



### 2.2 适用范围

该工具适用于监控 DM7 数据库和 DM8 数据库。

### 2.3 工具下载

DEM 监控工具可通过拨打达梦咨询热线 400 991 6599 申请获取。

### 2.4 DEM 部署

#### 2.4.1 环境准备

1. 硬件环境

（1）服务器：实体机或虚拟机；

（2）操作系统：Windows 或 Linux 操作系统均可；

（3）内存：建议提供 2G 以上内存；

（4）其他：由于 DEM 会从被监视的数据库中获取信息到后台数据库，因此，建议生产环境中 DEM 数据的存储目录应不小于 100GB；其余的硬件要求与数据库单机部署一致。

2. 软件环境

（1）DEM WAR 包：申请获取；

（2）Tomcat：自备，要求与部署的系统环境相匹配；

（3）JAVA 1.8：DEM 和 dmagent 所在机器需要配置 JAVA 环境，JAVA 版本必须为 JAVA 1.8。若系统中不带 jdk 环境可以在环境变量中指定数据库中的 jdk 目录即可，如下所示：

```
[root@localhost ~]# cat /etc/profile
export JAVA_HOME=/home/dmdba/dm/dmdbms/jdk
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
```

（4）达梦数据库：为 DEM 的后台数据库，需保证 DEM 所在机器能访问达梦数据库。

在部署 dmagent 之前，需设置 DEM 和 dmagent 所在服务器主机的时间同步。正式环境建议使用 ntp 配置时间同步。如下以 ”10.10.10.10“ 为 ntp 服务器为例，设置定时任务：

```
[root@localhost ~]# crontab -l
# Time sync
0,10,20,30,40,50 * * * * /root/sync_time.sh
[root@localhost ~]# cat /root/sync_time.sh 
#!/bin/bash
. /etc/profile
. /root/.bash_profile
ntpdate 10.10.10.10 ; hwclock –w
```

#### 2.4.2 初始化后台数据库

  1. 创建后台数据库。创建一个 DM 数据库作为 DEM 后台数据库，初始化参数不做要求，默认即可，对数据库的 dm.ini 参数配置进行优化，推荐配置如下：



```
MEMORY_POOL         	=  200
BUFFER                  		=  1000
KEEP                    		=  64
SORT_BUF_SIZE          	=  50
```

  2. 执行初始化脚本。在创建的后台数据库中用 SYSDBA（或管理员用户）执行 SQL 脚本 dem_init.sql，脚本位于达梦安装目录下"../web/dem_init.sql"（此 SQL 脚本编码为 UTF-8，若使用 disql 执行 SQL 脚本，请先设置 \` set CHAR_CODE UTF8\`）。执行完脚本后，在后台数据库中会生成一个 DEM 的模式，存放 DEM 运行所需要的表和视图。
  3. 备份策略。可根据实际项目需求确定是否有必要设置后台数据库的备份，并确定备份策略。



#### 2.4.3 配置 Tomcat

  1. 解压 tomcat 包。安装完 tomcat 之后，会生成以下目录：



```
[dmdba@localhost apache-tomcat-7.0.75]# ll
总用量 144
drwxr-x--- 2 dmdba dinstall  4096  8月 27 09:28 bin
drwx------ 3 dmdba dinstall  4096  8月 31 09:32 conf
drwxr-x--- 2 dmdba dinstall  4096  8月 27 09:15 lib
-rw-r----- 1 dmdba dinstall 57092  9月  5  2018 LICENSE
drwxr-x--- 2 dmdba dinstall  4096  9月  3 09:46 logs
-rw-r----- 1 dmdba dinstall  1726  9月  5  2018 NOTICE
-rw-r----- 1 dmdba dinstall  7142  9月  5  2018 RELEASE-NOTES
-rw-r----- 1 dmdba dinstall 16262  9月  5  2018 RUNNING.txt
drwxr-x--- 2 dmdba dinstall  4096  8月 27 09:15 temp
drwxr-x--- 8 dmdba dinstall  4096  8月 27 09:32 webapps
drwxr-x--- 3 dmdba dinstall  4096  8月 27 09:32 work
```

  2. 检查 JAVA 环境。启动之前需要确定配置 JAVA 1.8 及以上版本的运行环境，运行 \`java –version\` 查看 JAVA 版本。



```
[dmdba@localhost ~/apache-tomcat-7.0.75]$ java -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)
```

  3. 修改 tomcat 配置。



（1）在 conf/server.xml 配置文件中 `<Connector port="8080" protocol="HTTP/1.1"...` 位置处添加属性字段 `maxPostSize="-1"`。

```
<Connector port="8080" protocol="HTTP/1.1" maxPostSize="-1"
               connectionTimeout="20000"
              redirectPort="8443" />
```

（2）在 bin/catalina.sh 配置文件中，根据数据库的安装路径，修改 jvm 启动参数。

```
Linux：bin/catalina.sh -> 	JAVA_OPTS="-server -Xms256m -Xmx1024m -Djava.library.path=/home/dmdba/dmdbms/bin"
Windows：bin/catalina.bat -> set java_opts= -server -Xms40m -Xmx1024m -Djava.library.path=c:\dmdbms\bin
```

#### 2.4.4 DEM 连接配置

  1. 解压 dem.war 包。



将 dem.war 包放置在 Tomcat 的 webapps 目录下，启动 Tomcat，会自动解压 war 包生成 DEM 目录。在 bin 目录下执行脚本启动 Tomcat。

```
[dmdba@localhost ~/apache-tomcat-7.0.75/bin]$ ./startup.sh
Using CATALINA_BASE:   /home/dmdba/apache-tomcat-7.0.75
Using CATALINA_HOME:   /home/dmdba/apache-tomcat-7.0.75
Using CATALINA_TMPDIR: /home/dmdba/apache-tomcat-7.0.75/temp
Using JRE_HOME:        /usr
Using CLASSPATH:       /home/dmdba/apache-tomcat-7.0.75/bin/bootstrap.jar:/home/
dmdba/apache-tomcat-7.0.75/bin/tomcat-juli.jar
Tomcat started.
```

  2. 配置后台数据库连接。



配置后台数据库的连接信息：ip、port、用户名、密码、连接池大小、SSL 登录信息等，在文件 dem/WEB-INF/db.xml 配置。

```
[root@localhost WEB-INF]# cat db.xml
<?xml version="1.0" encoding="UTF-8"?>
<ConnectPool>
        <Server>10.9.XXX.XXX</Server>
        <Port>5236</Port>
        <User>SYSDBA</User>
        <Password>SYSDBA</Password>
        <InitPoolSize>5</InitPoolSize>
        <CorePoolSize>10</CorePoolSize>
        <MaxPoolSize>50</MaxPoolSize>
        <KeepAliveTime>60</KeepAliveTime>
        <DbDriver></DbDriver>
        <DbTestStatement>select 1</DbTestStatement>
        <SSLDir>../sslDir/client_ssl/SYSDBA</SSLDir>
        <SSLPassword></SSLPassword>
</ConnectPool>
```

如果需要 SSL 安全方式连接后台数据库，则要配置 SSLDir 和 SSLPassword：默认在 WEB-INF/sslDir 目录存有密钥对，WEB-INF/db.xml 配置客户端连接使用的密钥文件（SSLDir）为 WEB-INF/sslDir/client_ssl/SYSDBA，密码 ( SSLPassword ) 为空，对应 WEB-INF/db.xml 配置的登录用户 SYSDBA，此时，只需拷贝 `WEB-INF/sslDir/server_ssl` 到后台数据库执行码目录。

db.xml 中 Password 和 SSLPassword 支持设置自定义加解密引擎对密码进行加解密处理，通过属性 engine 指定加解密引擎类路径。自定义加解密引擎需要实现 demsdk.jar 中提供的 com.dameng.dem.server.util.IEncryptEngine 接口。将自定义加解密引擎打包成 jar 文件放入 WEB-INF\\lib 目录下。

demsdk.jar 提供了一个默认的加解密引擎：com.dameng.dem.server.util.DefaultEncryptEngine，使用默认加解密引擎配置如下：

```
<Password engine="com.dameng.dem.server.util.DefaultEncryptEngine"> 通过 DefaultEncryptEngine 加密后的密码</Password>
```

  3. 配置 DEM 日志级别。



在 tomcat 的 webapps/dem/WEB-INF 目录下，log4j.xml 文件控制着日志级别。LOG_LEVEL 参数控制日志的显示信息，LOG_MAX_SIZE，LOG_MAX_COUNT，LOG_PRESERVE_DURATION 这 3 个参数动态组合控制日志量和日志保存的最大大小，超过这个最大大小的日志会被删除。

```
日志最大大小= LOG_MAX_SIZE × LOG_MAX_COUNT × LOG_PRESERVE_DURATION；
```

在 DEM 调试和查找问题时，LOG_LEVEL 可以使用 DEBUG 或者 ALL 参数，生产环境建议使用 ERROR 级别。根据项目的实际需要和磁盘的可用大小，调整 LOG_MAX_SIZE，LOG_MAX_COUNT，LOG_PRESERVE_DURATION 这 3 个参数的大小，避免出现磁盘爆盘的现象。此配置文件重启 Tomcat 之后才能生效。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009145448EIFO3PY1ZGURQVVCWL)

  4. 重启生效。重新启动 Tomcat 使配置生效。



#### 2.4.5 部署 dmagent

部署 dmagent 之前，需要确定服务器配置 JAVA 1.8 及以上版本的运行环境，运行 `java –version` 查看 JAVA 版本，核对 dmagent 机器和 dem 运行机器的时间一致。

  1. 获取 dmagent。dmagent 有两种获取方式：  
（1）达梦数据库安装目录的 tool 下存有 dmagent。  
（2）登录部署好的 DEM，在资源包中下载 dmagent 压缩包。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522150210MYPRNNSWKR4X5RY5H6)

  2. 拷贝 dmagent 到要部署的机器上。
  3. 修改 dmagent 配置。配置 dmagent 目录下的 agent.ini：



```
##dem 所在机器的地址
center_url  =  http://192.168.XXX.XXX:8080/dem
##dmagent所在服务器的地址 
ip_list     = [192.168.xx.xx]   
```

  4. 配置 dmagent 日志级别。同样修改 dmagent 目录下的 log4j.xml 文件，修改方法与 dem 端相同。
  5. 启动 dmagent。



```
Linux：bin/start.sh –d  agent.ini
Windows：start.bat –d  agent.ini
```

  6. 脚本注册与服务启动（选做）：



```
##注册服务
[root@localhost dmagent]# ./service.sh install
input agent home [/home/dmdba/dm/dmdbms/tool/dmagent] :
input agent.ini path [/home/dmdba/dm/dmdbms/tool/dmagent/agent.ini] :
input service user [dmdba] :root
installation the service DmAgentService completed.
##以服务的方式启动 dmagent
[root@localhost dmagent]# cd service/
[root@localhost service]# ./DmAgentService start
Starting dmagentStarting dmagent.....
dmagent(pid: 28641) started successfully.
 SUCCESS!
```

#### 2.4.6 其他

客户端工具显示。若要求不显示 manager 客户端工具，则在 tomcat/bin/catalina.sh 文件中追加属性字段 `JAVA_OPTS=”…… -Drun_mode=DMA”`。配置成功后则不会显示实例连接。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221010092558LLLJAPV71KW5CWJ6OG)

### 2.5 工具使用

#### 2.5.1 系统资源监控

1. 打开 DEM 工具

在浏览器输入 DEM 端 IP：端口 / DEM，默认用户和密码为 "admin/888888" ,登录到 DEM 页面中，如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240514150501SW6CVIS9PRRIWPU84P)

2. 功能介绍

登录 DEM 后，点击左侧导航栏中的【监控】-->【主机监控】可以展示主机的 CPU、内存、FIO、NIO、IO AWAIT 的使用情况如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520144723KOX6YNF2CN5DH45SYD)

此外从左侧导航栏中的【监控】-->【主机监控】点击相关实例的展开栏可以进行配置网络、升级代理、变更使用权、订阅、变更和删除的操作如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520151201G3L1V8753126RIN1MK)

可以从左侧导航栏中的【大盘】-->【单实例】展示系统的信息大盘包括实例名、运行时间等数据库基本信息还有数据库的健康提示，此外还展示了数据库中的会话、死锁数、等待事务数、重启次数、重要事件数等信息，下方还通过曲线展示了数据库的 session、TPS/QPS、CPU、Menory、FIO、NIO 等信息如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520150910MFOUL9TE33A8FPEIFN)

下方通过饼状图和柱状图的形式展示了数据库的联机日志、归档日志、数据文件、表空间信息如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520151035PBQ34XR4MUYKV9YUWY)

3. 负载统计

点击【监控】-->【主机监控】-->【负载分析】，页面中详细展示了当前系统的各项负载情况。用户可以查找 6 小时到过去一年（也可自定义时间范围）的负载统计信息，以折线图的方式展示包括内存和虚拟内存使用率、CPU 使用率、磁盘读和写的速率、网络发送和接收的速率。

用户可以通过折线图的走势直观的监控到系统负载的统计，如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520150522CWYY1FGRKF5GB2JJFM)

4. 磁盘分析

通过点击文件系统展示出各磁盘路径下使用率、空间大小和总大小。其中磁盘使用率通过下方折线图以系统时间点为横轴展示，同时也可以通过自定义时间节点完成统计情况展示如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202405201506294OYI0FT7CI2033K8MQ)

5. 自定义监控

可以通过添加自定义脚本的形式监控到程序或者脚本的执行时间、执行状态、最近的执行结果和执行信息，以满足特殊化监控需求。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520150744K1GNOAU3UFNFQNZFBD)

6. 进程监控

可通过设置名称和进程过滤条件，添加进程监控，进程组监控，实时监控进程运行情况。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240520151335JQSD98IEKY06Y5GDS8)

#### 2.5.2 数据库监控

1. 功能介绍

点击【监控】-->【数据库监控】-->【负载分析】可进行数据库基本信息查看，总览中可以调取任意时段的数据库 CPU 曲线、MEM 曲线、NIO 曲线、FIO 曲线、TPS 曲线、QPS 曲线、等待任务数曲线和任务平均等待时间曲线。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522150846716771TCH7Y2SWYBRK)

此外点击数据库列表右侧展开图标支持一键启停、配置变更、卸载数据库、巡检数据库、升级数据库（key 或执行码）、导出堆栈或运行日志、变更使用权（公有、私有）订阅等功能。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522150915I8UN5H7FLSMDK9YT9H)

2. 表空间分析

可选择任意时间段的表空间使用及配置情况，包括表空间使用率、空闲大小、总大小、最大大小、文件数、自动扩展、完整路径等信息，下方还通过曲线图的形式展示了 SYSTEM、ROLL、TEMP、MAIN 表空间的使用率。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202405221511277BEVMXG8FKEQLC8DVY)

3. SQL 分析

SQL 分析可监控数据库中指定时间段内，出现的慢 SQL、高频 SQL 错误 SQL 和审核 SQL 情况。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522151233YPZBAP7DK10JKWEKUX)

4. 会话分析

会话分析可以展示任意时段数据库的会话数曲线图，并抓取会话 ID、SQL_ID、SQL 语句、用户、应用名称等信息。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522151525SPLBIFAG229AZRDUKR)

5. 事务分析

事务分析展示了任意时段内数据库中的死锁、等待事务、锁数等信息。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522151822NCG6I2H1DQYYNNEPBX)

6. 运行日志分析

运行日志分析展示了任意时段的数据库日志情况，可以通过日志类型筛选筛选出数据库不同等级的告警。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/2024052215194506NCKMN2W7SBDNLJTA)

7. 联机日志分析

联机日志展示了任意时段的联机日志情况、LSN、刷盘情况、刷盘次数。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202405221521171D5HI4FQNOP7SUAB7X)

8. 归档分析

归档分析展示了归档等待任务数、归档任务平均等待时间、归档文件大小增长速率情况。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522152238G1J5DZGK07PXQIDLBZ)

9. 事件分析

事件分析展示了数据库任意时段的累计等待时间折线图和相关事件详情列表。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522152401TPXVQ611UL2SI7H48M)

10. 登录锁定分析

登录锁定分析展示了任意时段的用户 ID、用户名、状态、最后锁定时间和锁定时长信息。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522152535I9FCYSDXS421YGW66H)

12.作业分析

作业分析展示了任意时段的数据库的作业历史和执行情况。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522152653T1K360WWTQW7FT3FCR)

13.自定义监控

自定义监控展示了任意时段添加的自定义监控 SQL 的执行结果和自定义 SQL 执行历史曲线图，以及 SQL 的查询频率、结果、状态和耗时情况。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202405221531126L4YJWH66N5BGMBO8O)

#### 2.5.3 告警配置

点击【告警配置】->【添加】，可额外设置监控告警选项，同时还可配置告警邮箱，当某项指标超出阈值点时，可将告警信息发送到指定邮箱，便于及时获取系统风险点，并采取应急措施。

若要启用邮件通知，需用管理员用户登录系统，在系统配置中完成系统邮箱的相关配置。若需要启用短信通知，则需要借助 WEB-INF/lib/demsdk.jar 文件，实现 com.dameng.dem.server.util.IPhoneNotify 接口，将依赖包及实现类打包放入到 WEB-INF/lib 下，重启 web 容器，并在系统配置中完成短信通知的相关配置即可。

本模块可根据系统具体要求添加告警，并设置告警策略。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522154226UEU0ABOADISK8O9421)

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202405221542570WTXDIIU55TTMLFRAX)

邮件和短信提醒可以在系统管理系统配置中进行设置。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522154318HUP9DB4DWGFBLYLWCP)

#### 2.5.4 注意事项

  1. DEM 和 dmagent 版本需要保持一致，且两端系统时间也应一致，否则会出现无法显示主机信息等情况。
  2. 在生产环境中，建议不要使用 SYSDBA 用户连接，建议创建独立的 DEM 用户，给予相应表和视图的查询权限，并限制最大会话数和会话空闲期。监控用户不要配置 any 等过大权限。以 test 用户为例：



```
--授予DEM监控数据库最小连接权限：
create user "TEST" identified by "******" limit session_per_user 50, connect_idle_time 10;
grant "PUBLIC" to "TEST";
grant SELECT TABLE,SELECT VIEW,SELECT SEQUENCE to "TEST";
```

  3. 生产环境中建议根据实际情况进行监控项配置。数据库死锁、数据库事件、高频 SQL、出错 SQL、慢 SQL、表空间、用户锁等信息，请按需求进行监控设置。
  4. 历史数据清除。DEM 在运行一段时间后会产生历史数据，会占用磁盘空间，可通过以下两种方法定时清理历史数据，达到释放空间的效果。



  方式一：通过 Web 页面进行设置定时清理。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202405221544142859DS2O32C5RJFQJL)

  方式二：通过设置数据库定时任务，按需配置需要清理的表，定时清理历史数据。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522154519FMF8MS7646C32OVJ8W)

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522154555V0R9P2YWV72SF5RQVU)

相关定时任务 SQL 语句如下：

```
call SP_CREATE_JOB('DEL_DEM_HIS',1,0,'',0,0,'',0,'');
call SP_JOB_CONFIG_START('DEL_DEM_HIS');
call SP_ADD_JOB_STEP('DEL_DEM_HIS', 'DEL_DEM_HIS', 0, 'truncate table "DEM_TSD"."ALERT_HIS";
truncate table "DEM_TSD"."DATABASE_ARCH_FILE";
truncate table "DEM_TSD"."DATABASE_AUDITRECORD";
truncate table "DEM_TSD"."DATABASE_BACKUPSET";
truncate table "DEM_TSD"."DATABASE_GROUP_SQL";
truncate table "DEM_TSD"."MAINFRAME_STAT";
truncate table "DEM_TSD"."MAINFRAME_CORE";', 0, 0, 0, 0, NULL, 0);
call SP_ADD_JOB_SCHEDULE('DEL_DEM_HIS', 'DEL_DEM_HIS', 1, 2, 1, 1, 0, '01:00:00', NULL, '2022-03-04 15:56:01', NULL, '');
call SP_JOB_CONFIG_COMMIT('DEL_DEM_HIS');
```

## 三、达梦 SQL 日志分析工具 DMLOG

### 3.1 工具介绍

实例级 SQL 日志分析工具，DMLOG 工具是一款简单易用的达梦数据库 SQL 日志分析工具，通过分析数据库的 SQL 日志文件（达梦数据库可通过开启 SVR_LOG 捕捉数据库中运行的所有 SQL，并生成 SQL 日志文件），来统计日志中最长执行时间和执行最高频次的 SQL 语句，直观地反映 SQL 执行情况，对于 SQL 的优化工作提供了极大的便利。

DMLOG 工具可实现如下功能：

  * 达梦数据库 SQL 日志分析功能，统计分析日志并根据执行时间和执行频次进行排序，生成 excel 文档。
  * 支持生成 echart 散点图，每个点上的 sql 可以显示和拷贝。
  * 支持生成 sql 统计图，根据执行次数和执行时间统计。



### 3.2 适用范围

  * DMLOG 工具不受操作系统平台限制，大小不超过 10M，在安装好 Java 环境后，可在各平台运行。
  * DMLOG 工具适用于各种版本的 DM7 数据库和 DM8 数据库。



### 3.3 工具下载

DMLOG 工具可自行在 [在线服务平台 VIP 专区](https://eco.dameng.com/vip/) 下载或联系达梦技术服务人员获取。

### 3.4 工具使用

#### 3.4.1 使用条件与限制

  1. 运行环境需预先安装 Java 环境，DMLOG 支持在 Liunx 和 Windows 系统运行。推荐使用 java1.8 版本，linux 最小化安装最少要安装打印服务组件，windows 下不支持 java1.6 版本。
  2. SQL 日志格式要求确保每条语句后紧跟 sql 语句时间，因此需确认日志生成的数据库的 sql trace 参数，建议使用默认参数。
  3. 由于程序运行需要在后台数据库建 log_commit 表，建表前会删除同名表，因此如果有同名表，请先做好备份。
  4. 待分析的 SQL 文件夹中请保证只有 SQL 日志，无其他文件。
  5. dmlog.properties 配置文件中 log 路径，注意 windows 下，使用”\\\\\\”代替”\\”。
  6. 由于一页 excel 最大行数为 65536，因此当待分析的日志量较大时，会提示超过限值警告，只取前 65535 记录。此时可以将日志切割或分批进行分析，或者分析执行时间比较长和执行时间比较高的 SQL，也可以不使用替换参数功能，减少输出结果。



> **警告**
>
> 本工具只能在测试环境进行分析，切忌连接生产环境！！！



#### 3.4.2 使用前准备

使用前需检查 Java 安装情况。

```
[root@localhost DMLOG8.3]# su - dmdba
Last login: Tue Oct 12 11:20:08 CST 2021 on pts/1
[dmdba@localhost ~]$ java -version
openjdk version "1.8.0_181"
OpenJDK Runtime Environment (build 1.8.0_181-b13)
OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)
```

#### 3.4.3 使用方法和步骤

  1. 解压工具包并配置工具参数。



```
[root@localhost /]# unzip DMLOG8.*.zip
[root@localhost /]# cd DMLOG8.*/ 
[root@localhost DMLOG8.10]# vi dmlog.properties
```

> **注意**
>
> Windows 环境下，dmlog.properties 配置文件中 log 路径 sqlpath 参数，需使用”\\\\\\”代替”\\”，liunx
> 下填写正常路径即可。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522154939PEGBWAOYHGX7TK96E1)

  2. 执行 jar 包命令。



```
[root@localhost DMLOG8.**]# java -jar Dmlog_DM_8.**.jar
```

运行过程如下图所示，执行完成后会按当前时间生成对应 RESULT_$DATE 文件夹，并将所有统计信息都存放该目录中。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/2024052215510785JX7PFBABY58R35A4)

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522155215BX4QWDWGD32Z3C6HAW)

#### 3.4.4 结果解读

生成的 RESULT_$DATE 结果文件夹下有根据配置的执行时间和执行次数上限值命名的 excel 文件(xls)、报错的 SQL 文件（txt）、长度超过 30000 的 SQL 文件 (txt)，echart 散点图及 90% 平均次数和平均耗时的 SQL 统计图 (html)。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522155332OHIA2HLVLBYGEI7B1W)

  1. more_than_0_ms_log_result.xls 工作表按照最大执行时间降序排序，如下图。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522155424GNOFV4QDGKS4GD3T4Y)

  2. more_than_0_times_log_result.xls 工作表按照执行次数降序排序，如下图。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522155501T5O80KP2TFZDEG1H2E)

  3. echarts_scatter_loading10.html 为 echart 散点图每个点的 SQL 信息可以显示和拷贝，如下图。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522155525IUU76JTHLFJNY5O60S)

散点图支持以下功能：

（1）筛选 SEL/DDL/INS/CAL 等分类，只用点击去除或者选择对应类别，即可显示对应 sql 在图形上分布点。

（2）支持散点图区域放大功能，鼠标指定位置，进行滚轮缩放，可放大语句。

（3）点击每个点，可获得每个点的 SQL 详细信息。

（4）点击散点图右上角可以保存图片。

  4. echarts_scatter_Statistics.html 为散点图基础上生成的按照执行 90% 平均次数和平均耗时的 SQL 统计图。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20240522155546S5N0SN0WR81JLEZXGJ)

  5. echarts_qps.html 为 QPS（Queries-per-second，即每秒查询率，在数据库中指每秒执行查询 sql 的次数）折线图。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/2024052215560585Q0Y23YXPDSR8UJ3R)

## 四、开源性能监控工具 NMON（Linux）

### 4.1 工具介绍

nmon 是一种在 AIX 与各种 Linux 操作系统上广泛使用的监控与分析工具。相对于其它系统资源监控工具来说，nmon 所记录的信息较为全面，它能在系统运行过程中实时地捕捉系统资源使用情况，输出结果文件，并通过 nmon_analyzer 工具产生数据文件与图形化结果。一般 nmon 监控系统资源包括 cpu 占用率、内存使用情况、磁盘 I/O 速度、传输和读写比率、文件系统的使用率、网络 I/O 速度、传输和读写比率、错误统计率与传输包的大小、消耗资源最多的进程、计算机详细信息和资源等相关信息。

### 4.2 适用范围

该工具适用监控 Linux 系统资源使用情况。

### 4.3 工具下载

NMON 和 nmon_analyser 工具可在 [NMON 官网](http://nmon.sourceforge.net)下载。

### 4.4 NMON 部署

  1. 将 nmon 文件上传至自定义目录下例如 /opt/tool 目录下，然后执行 \` ./nmon\`，出现以下界面说明当前环境可以正常运行。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221010111709N4DM7V6H23XMOK3DU4)

  2. 设定定时计划实时监控系统资源。



```
##使用 root 用户执行
crontab -e

##添加以下脚本内容，实时监控系统资源并生成 NMON 日志文件。-s20 表示 20s 采集一次，-c4320 表示一天 24 小时采集 4320 次
0 0 * * * /opt/tool/nmon -s20 -c4320 -fT -m /opt/tool/nmon_log > /dev/null 2>&1

##添加以下脚本内容，设定定时删除计划，保留某时间段内的日志，防止空间占满。+365 为保留时间，日志具保存时长，需根据系统实际情况而定
0 0 * * * find /opt/tool/nmon_log  -type f -mtime +365  -name "*.nmon" -exec rm -f {} \;
```

### 4.5 工具使用

#### 4.5.1 NMON 日志分析

NMON 工具部署完成后，即可对系统状态进行监控，生成监控日志文件。NMON_ANALYZER 工具通过 excel 的宏命令分析加载生成 excel 图表，展示资源占用的各项信息。使用过程中可通过图表信息直观地查看系统资源使用情况。

使用方法：打开 nmon analyser v66.xlsm，使用 analyze nmon data 打开所需要分析的 nmon 日志文件，分析完成后保存成 excel 文件，即可查询系统资源的图表信息。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221010111744KJXE2L91H4TVS3MXK4)

#### 4.5.2 结果解读

以下提供某系统中 NMON 监控一段时间后，利用 NMON_ANALYZER 工具分析生成的 Excel 报表，详细介绍该报表中多个子表的含义，以供参考。

1. 系统资源使用汇总

SYS_SUMM 子表显示了系统资源的总体使用情况，页面主要信息如下：

左纵轴为系统 cpu（user%+sys%）使用率，横轴为运行时长，右纵轴为系统磁盘传输（Disk xfers），蓝线表示系统 cpu 使用情况，粉红线表示系统 I/O 情况。坐标左下侧为统计信息，涉及系统 I/O 情况（一个采集间隔内的平均值、最大值、出现最大值的时间），系统 CPU 使用情况等。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202210091403339I9AEGR1YCUFY0H4OK)

2. 系统信息

AAA 子表显示了系统基本信息，主要包括：执行命令，主机 CPU 数，操作系统内核版本信息，主机名等内容。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202210091416086HYVGRA8NUBPV9V411)

3. 磁盘信息汇总

DISK_SUMM 子表为系统磁盘信息汇总。主要包含以下内容：

（1）Disk total KB/s 表示执行间隔时间列表；

（2）Disk Read KB/s 表示采集间隔内磁盘设备的读速率；

（3）Disk Write KB/s 表示采集间隔内磁盘设备的写速率；

（4）IO/sec 表示采集间隔内磁盘整体平均每秒 IO 数。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009141749RFXZPGAU9VEG9ZU5Y0)

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009141756O56AYFLM85V4QLHTEX)

4. CPU 整体情况

CPU_ALL 子表为 CPU 整体情况的统计。主要包含以下内容：

（1）CPU Total：执行间隔时间列表；

（2）User%：采集间隔内所有 CPU 在 User Mode 下的 Time 占比（Avg、Max）；

（3）Sys%：采集间隔内所有 CPU 在 System Mode 下的 Time 占比（Avg、Max）；

（4）Wait%：采集间隔内所有 CPU 处于空闲且等待 I/O 完成的时间比例（Avg、Max）；

（5）Idel%：采集间隔内所有 CPU 处于空闲 Time 的占比（Avg、Max），此值和 User%，Sys%，Wait% 及 Steal% 之和等于 1；

（6）CPU%：CPU 总体占用情况，这个值通常等于 User%+Sys%；

（7）CPUs：操作系统的 CPU 核数。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009141951YQYLOGRCWEV0ZQQ6GO)

5. 内存情况

MEM 子表统计了系统的内存使用情况。主要包含以下内容：

（1）memtotal：物理内存总大小，单位 MB；

（2）swaptotal：虚拟内存（即交换空间）的总大小；

（3）memfree：剩余物理内存大小；

（4）swapfree：剩余虚拟内存大小；

（5）cached：物理内存中被 cache 占用的缓存大小；

（6）active：在活跃使用中的内存大小；

（7）buffers：文件系统缓冲区的大小；

（8）swapcached：虚拟内存中被 cache 占用的缓存大小；

（9）inactive：不常使用的内存大小。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009142254Y2SM9BOELLHSEGR1PT)

NET/NETPACKET 子表为系统网络情况汇总。反映系统的网络运行情况，系统各个网络适配器读写的数据包数；NET 页面显示系统中每个网络适配器的数据传输速率（千字节/秒）。

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009142347WUSHK1E5OQN695GQNT)

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009142416Z5L8BNBB1NWQGYYCB0)

7. 磁盘繁忙度

DISKBUSY 子表显示了系统磁盘繁忙度信息。

（1）正常情况，如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009142542Z6C8SHW8WM8R080499)

图中 dm2 对应磁盘 dbdata，dm1 对应 dbarch，dm0 对应 dbbak，从中我们可以看出在下班时间段，磁盘 IO 波动较大，但多数时间仍有空闲，上班时间段时磁盘 IO 几乎保持为 100% 繁忙状态，说明业务本身对数据库的读写压力就比较大。

（2）异常情况，如下图所示：

![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221009142634SRI78C4CA0PEY3MFWY)

图中从 10 点 25 分开始，IO 繁忙度持续保持为 100% 状态，长时间的满繁忙度，会导致数据库读写变慢，阻塞应用的读写操作，使得应用读写变慢，从而导致相关问题；这种情况需要对应用业务和数据库的事务进行分析，也需要结合磁盘的读写速度进行分析，可能是磁盘读写性能下降导致此类问题，也可能是异常事务或者新上的业务导致数据库的读写压力过大。

## 五、开源运维监控工具 Prometheus

### 5.1 工具介绍

Prometheus 是由 SoundCloud 开发的开源监控报警系统和时序列数据库 (TSDB)。Prometheus 使用 Go 语言开发，是 Google BorgMon 监控系统的开源版本。Prometheus 的基本原理是通过 HTTP 协议周期性抓取被监控组件的状态，任意组件只要提供对应的 HTTP 接口就可以接入监控。

Prometheus 适用于记录文本格式的时间序列，它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。Prometheus 是专为提高系统可靠性而设计的，它可以在断电期间快速诊断问题，每个 Prometheus Server 都是相互独立的，不依赖于网络存储或其他远程服务。

DEM 为 Prometheus 提供了数据收集功能，通过在 dem 中配置监控资源，便可以生成 metrics 数据，供 Prometheus 平台使用。

### 5.2 适用范围

Prometheus 工具适用于监控 DM7 数据库和 DM8 数据库。

### 5.3 工具下载与安装

Prometheus 软件下载与安装详细内容见 [Prometheus 官网](https://prometheus.io/docs/introduction/overview/)。

### 5.4 Prometheus 连接 DEM

DEM 为 Prometheus 提供了数据收集功能，通过在 dem 中配置监控资源，便可以生成 metrics 数据，供 Prometheus 平台使用。使用方法如下：

  1. 安装 DEM。DEM 部署详细步骤见 2.4 节 DEM 部署。
  2. 从 DEM-> 系统-> 系统配置-> 其他功能->prometheus_metric_nodes，设置需要推送的数据库实例监控信息。
  3. 配置 prometheus.yml 文件，去 dem/metrics 获取监控数据，如下：



```
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
    - targets: ['192.168.142.217:9100']
      labels:
         group: 'client-node-exporter'
    - targets: ['192.168.142.217:9161']
      labels:
         group: 'dmdb-node-exporter'
  - job_name: 'dem'
    metrics_path: '/dem/metrics'
    static_configs:
    - targets: ['192.168.142.241:8080']
```

  4. Prometheus 获取到对应信息。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/202210101002517RQZ48Z7UTO9YU3N4E)

  5. 查看 Prometheus 获取到的数据，可以通过 console 来获取到 PromQL 查询语句。



![image.png](https://eco.dameng.com/eco-file-server/file/eco/preview/20221010100302I8DCM8OFACE04VGQYQ)

## 六、参考

以上监控工具使用过程中遇到任何问题，可到 [达梦技术社区](https://eco.dameng.com/community/question/) 提问交流。
